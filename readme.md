# ğŸ§  AI Document Creation System

An intelligent platform for **AI-powered document generation** using templates, agents, and retrieval-based knowledge grounding.  
Designed to produce accurate, consistent, and customized documents such as reports, proposals, or contracts.

---

## ğŸš€ Overview

This project enables users to **create, manage, and generate documents** automatically using predefined templates and AI agents.  
The system integrates:
- Template-based text composition
- Contextual data retrieval (RAG)
- Multi-agent orchestration for writing, reviewing, and validating
- Feedback loops for continual improvement

---

## ğŸ§± System Architecture
```bash
User â†’ Frontend â†’ API Gateway / Orchestrator â†’ AI Agent Layer â†’
â”œâ”€â”€ Template Manager
â”œâ”€â”€ Context Retriever (RAG)
â”œâ”€â”€ Document Composer
â””â”€â”€ Validation & QA Agent
â†“
Storage: Templates, Documents, Vector DB, User Data
```
---

## âš™ï¸ Core Components

### 1. Template Manager
Handles template creation, storage, and parsing.

- Supports placeholders like `{{client_name}}`, `{{project_description}}`
- Enables version control and reusable formats

**Tech stack:**
- Frontend: React + TipTap + Yjs for rich text editing and real-time collaboration  
- Backend: FastAPI (async support, type safety, automatic docs)  
- Database: PostgreSQL  
- Cache: Redis (for response caching and session state)

---

### 2. AI Agent Layer
The intelligent core that drives document generation.

#### Agents (MVP: Start with 2, expand later):
- **Document Composer Agent** â€” Generates drafts from templates  
- **Validation Agent** â€” Checks logic, consistency, and grammar  
- *(Phase 2)* **Knowledge Agent (RAG)** â€” Retrieves relevant contextual info  
- *(Phase 3)* **Critique Agent** â€” Improves clarity, tone, and structure  

#### Tools:
- **LangGraph** for lightweight AI workflow orchestration  
- **Redis** for state management and caching  
- **Celery** or **BullMQ** for background job processing

**Performance Strategy:**
- **Streaming responses** â€” Show partial results as they generate
- **Parallel execution** â€” Run independent agents concurrently
- **Prompt caching** â€” Cache system prompts to reduce costs by 50-90%
- **Model selection** â€” Use GPT-4o for generation, GPT-4o-mini for validation

---

### 3. Context & Knowledge Layer (RAG)
Ensures factual accuracy and domain relevance.

- Stores background material, reference docs, brand guides, etc.
- Uses vector embeddings for semantic search
- Filters results based on metadata (e.g., type, category, date)

**Tech options:**
- Vector DB: **Qdrant** (fast, open-source) or **PostgreSQL + pgvector** (simpler stack)
- Embeddings: OpenAI text-embedding-3-small or Hugging Face  
- **Hybrid search** â€” Combine semantic + keyword search for better accuracy
- **Reranking** â€” Use Cohere Rerank API or local model to improve top results
- **Metadata filtering** â€” Filter by doc type/date before vector search

---

### 4. Document Generator
Merges the AI-generated content with structured templates.

**Libraries:**
- `python-docx` / `docxtpl` â€” for Word docs  
- `WeasyPrint` or `Typst` â€” for modern HTMLâ†’PDF conversion  
- `Jinja2` â€” for HTML or Markdown templates  

**Export formats:** PDF, DOCX, HTML, Markdown

Includes post-processing to ensure consistent formatting and styling.

---

### 5. Validation & Feedback Layer
Provides high accuracy and control over generated output.

#### Techniques:
- **Fact-checking:** Compare claims with retrieved context  
- **Consistency checks:** Detect section mismatches or conflicting statements  
- **Style & tone validation:** Ensure brand or professional consistency  

#### Tools:
- **Ragas** â€” Response evaluation metrics  
- **TruLens** â€” AI evaluation and feedback loops  
- **Guardrails.ai** â€” Schema validation and safety checks  

---

## ğŸ§  Advanced Techniques

| Technique | Description | Priority |
|------------|-------------|----------|
| **Streaming responses** | Show partial results as they generate | ğŸ”´ MVP |
| **Prompt caching** | Cache system prompts to reduce costs by 50-90% | ğŸ”´ MVP |
| **Structured prompting (JSON schema)** | Ensures predictable, parseable AI outputs | ğŸ”´ MVP |
| **Background job processing** | Queue long-running tasks, don't block API | ğŸ”´ MVP |
| **Response caching (Redis)** | Cache generated sections for similar requests | ğŸŸ¡ Phase 1.5 |
| **RAG (Retrieval-Augmented Generation)** | Grounds content in real data | ğŸŸ¡ Phase 2 |
| **Hybrid search + reranking** | Better retrieval accuracy | ğŸŸ¡ Phase 2 |
| **Multi-agent orchestration** | Modular agent-based document creation | ğŸŸ¢ Phase 3 |
| **Human-in-the-loop feedback** | Learn from user corrections | ğŸŸ¢ Phase 3 |
| **Fine-tuning / LoRA adapters** | Tailor tone and accuracy for specific domains | âšª Phase 4 |
| **Tool use & APIs** | Agents can call external APIs (CRM, calendar, etc.) | âšª Phase 5 |
| **Semantic memory** | Maintain long-term personalization | âšª Phase 5 |

---

## ğŸ’» Tech Stack (Optimized)

| Layer | Tools / Frameworks | Why |
|-------|--------------------|-----|
| **Frontend** | React + Tailwind + TipTap + Yjs + SWR | Modern editor with real-time collab + efficient caching |
| **Backend API** | **FastAPI** | Async support, type safety, auto docs |
| **AI Layer** | OpenAI GPT-4o / GPT-4o-mini or Anthropic Claude | Use 4o for generation, mini for validation (cost savings) |
| **Vector Database** | **Qdrant** or PostgreSQL + pgvector | Fast & open-source OR simpler single-DB stack |
| **Cache & Queue** | **Redis** + **Celery** | Response caching, session state, background jobs |
| **Workflow Orchestration** | **LangGraph** | Lightweight AI workflow management |
| **Storage** | PostgreSQL + S3 | Structured data + document storage |
| **Auth & User Management** | Supabase Auth | Complete auth solution with minimal setup |
| **LLM Observability** | **Langfuse** or **Helicone** | Monitor token usage, costs, latency |
| **Evaluation & Safety** | Guardrails / Ragas / TruLens | Response validation and quality metrics |

---

## ğŸ§© Example User Flow

1. **Choose or upload a template**  
   â†’ e.g., â€œMarketing Proposalâ€  
2. **Enter context or structured data**  
   â†’ e.g., Client name, campaign type, budget, goals  
3. **AI Agents Run**  
   â†’ Compose â†’ Retrieve context â†’ Validate â†’ Style-check  
4. **User Reviews & Edits**  
   â†’ Interactive AI-assisted editor  
5. **System Learns**  
   â†’ Incorporates feedback to improve tone or format

---

## ğŸ§­ Development Roadmap

| Phase | Goal | Key Features |
|-------|------|-------------|
| **MVP** | Basic document creation with template merging | â€¢ Template CRUD<br>â€¢ Single LLM generation<br>â€¢ Streaming responses<br>â€¢ Prompt caching<br>â€¢ Background jobs |
| **Phase 1.5** | Performance & Cost Optimization | â€¢ Response caching (Redis)<br>â€¢ Token usage monitoring<br>â€¢ Export to PDF/DOCX/HTML |
| **Phase 2** | RAG-based context retrieval | â€¢ Vector DB integration<br>â€¢ Hybrid search + reranking<br>â€¢ Knowledge Agent<br>â€¢ Template marketplace |
| **Phase 3** | Multi-agent orchestration & validation | â€¢ Critique Agent<br>â€¢ Feedback loops<br>â€¢ Version control for documents<br>â€¢ Comments & approval workflows |
| **Phase 4** | Fine-tuning & personalization | â€¢ Domain-specific fine-tuning<br>â€¢ Style & tone customization<br>â€¢ Analytics dashboard |
| **Phase 5** | SaaS release | â€¢ Real-time collaboration<br>â€¢ Team workspaces<br>â€¢ API access<br>â€¢ Usage analytics |

---

## ğŸ”® Optional Cutting-Edge Features

- **Voice-based document creation** ("Create a proposal for Tesla in our usual tone")  
- **Real-time collaboration** with agent suggestions (via Yjs)  
- **AI Reviewer** for structure and clarity scoring  
- **Knowledge Graph integration** for structured factual grounding  
- **Multimodal generation** (text + visuals + charts)  
- **Incremental generation** â€” Generate by sections, not entire documents
- **Template versioning** â€” Track changes, compare versions, rollback
- **Approval workflows** â€” Route documents for review and sign-off

---

## ğŸ§° Example Tool Integrations

| Function | Tool | Notes |
|-----------|------|-------|
| Template rendering | Jinja2 / docxtpl | Dynamic placeholder replacement |
| RAG retrieval | LangChain + Qdrant | Hybrid search for better accuracy |
| Workflow orchestration | LangGraph | Lightweight for AI workflows |
| Background jobs | Celery + Redis | Async document generation |
| AI model integration | OpenAI / Anthropic | Prompt caching enabled |
| LLM monitoring | Langfuse / Helicone | Track costs, latency, quality |
| Evaluation | TruLens / Guardrails | Validate outputs, safety checks |

---

## ğŸ“š Example Directory Structure
```bash
ai-doc-system/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ hooks/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ composer.py
â”‚   â”‚   â”œâ”€â”€ validator.py
â”‚   â”‚   â””â”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â””â”€â”€ cache_service.py
â”‚   â”œâ”€â”€ tasks/              # Celery tasks
â”‚   â”‚   â””â”€â”€ generation.py
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ templates/
â”‚   â””â”€â”€ embeddings/
â”œâ”€â”€ docker-compose.yml   # Redis, PostgreSQL, Qdrant
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example

```
---

## ğŸš€ Performance Best Practices

### Cost Optimization
1. **Enable prompt caching** â€” OpenAI/Anthropic cache system prompts automatically
2. **Use model tiers strategically** â€” GPT-4o for generation, GPT-4o-mini for validation
3. **Cache similar requests** â€” Redis cache for frequently generated sections
4. **Batch processing** â€” Queue multiple documents for off-peak generation

### Speed Optimization
1. **Streaming** â€” Stream LLM responses to show partial results immediately
2. **Parallel execution** â€” Run independent agents concurrently
3. **Background jobs** â€” Use Celery for long-running document generation
4. **CDN for assets** â€” Serve static templates and documents from CDN

### Quality Optimization
1. **Hybrid search** â€” Combine semantic + keyword for better RAG results
2. **Reranking** â€” Improve retrieval precision with reranking models
3. **Monitoring** â€” Track generation quality with Langfuse/Helicone
4. **A/B testing** â€” Test different prompts and models

---

## ğŸ“¦ Setup & Run (Example)

```bash
# Clone repository
git clone https://github.com/your-org/ai-doc-system.git
cd ai-doc-system

# Environment setup
cp .env.example .env
# Edit .env with your API keys (OpenAI, etc.)

# Start infrastructure (Redis, PostgreSQL, Qdrant)
docker-compose up -d

# Backend
cd backend
pip install -r requirements.txt

# Start Celery worker (background jobs)
celery -A tasks worker --loglevel=info &

# Start FastAPI server
uvicorn app:app --reload

# Frontend (new terminal)
cd ../frontend
npm install
npm run dev
